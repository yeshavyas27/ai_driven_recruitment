{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: tqdm in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from sentence-transformers) (0.30.0)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\desktop\\ai_driven_recruitment\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/10.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/10.2 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.6/10.2 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.4/10.2 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.9/10.2 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.2 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.8/10.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.3/10.2 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.3/10.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.1/10.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 3.6 MB/s eta 0:00:00\n",
      "Using cached pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 3.5 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, setuptools, scipy, safetensors, Pillow, networkx, joblib, torch, scikit-learn, transformers, sentence-transformers\n",
      "Successfully installed Pillow-11.1.0 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.0.2 setuptools-78.1.0 sympy-1.13.1 threadpoolctl-3.6.0 torch-2.6.0 transformers-4.50.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# max sequence length of 256\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\ai_driven_recruitment\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yesha\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# model = SentenceTransformer(\"bert-base-nli-mean-tokens\")\n",
    "\n",
    "# model = SentenceTransformer(\"BAAI/bge-m3\")\n",
    "\n",
    "# model  = SentenceTransformer(\"all-distilroberta-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The sentences to encode\n",
    "sentence1 = ''' Developed end-to-end APIs on the server side. I also built full-fledged features including live chatting through\n",
    " sockets using SocketIO, grpc communication between microservices, and ios notifications\n",
    " • Tech Stack: Flask-Python, MongoDB, MySQL, Kong, Redis, AWS, Docker, SocketIO, RESTful APIs, Jira, Git,\n",
    " Ubuntu-linux '''\n",
    "sentence2 = ''' \n",
    "We are seeking skilled Backend Developers with a minimum of 1 year of development experience to join us as freelancers and contribute to impactful projects.\n",
    "\n",
    "Key Responsibilities:\n",
    "\n",
    "Write clean, efficient code for data processing and transformation.\n",
    "Debug and resolve technical issues.\n",
    "Evaluate and review code to ensure quality and compliance\n",
    "\n",
    "\n",
    "Required Qualifications:\n",
    "\n",
    "1+ year of Backend development experience.\n",
    "Proficiency in server-side languages (e.g., Python, Java, Node.js).\n",
    "Experience with database management (SQL, NoSQL).\n",
    "Understanding of RESTful API design.\n",
    "\n",
    "\n",
    "'''\n",
    "sentence3 = '''\n",
    "Bitbuffs Technologies Pvt. Ltd is looking for Front end developer Designing and implementing user-friendly and visually appealing web interfaces using HTML, CSS, and JavaScript.Building responsive designs that work on a variety of devices and screen sizes.Implementing interactive features such as forms, animations, and modals using JavaScript.Collaborating with back-end developers to integrate with APIs and server-side functionality.Debugging and fixing cross-browser compatibility issues.Optimizing website performance for speed and scalability.Writing clean, well-documented, and maintainable code.Participating in code reviews and contributing to team processes for continuous improvement.Should have excellent problem-solving, communication, and collaboration skills.\n",
    "'''\n",
    "\n",
    "sentence4  = '''\n",
    "\n",
    " SDEIntern\n",
    " CoRider- social ride-sharing app\n",
    " May 2023–Sep2023\n",
    " Remote\n",
    " • Developed end-to-end APIs on the server side. I also built full-fledged features including live chatting through\n",
    " sockets using SocketIO, grpc communication between microservices, and ios notifications\n",
    " • Tech Stack: Flask-Python, MongoDB, MySQL, Kong, Redis, AWS, Docker, SocketIO, RESTful APIs, Jira, Git,\n",
    " Ubuntu-linux\n",
    "\n",
    "'''\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embedding1 = model.encode(\"Flask-Python, MongoDB, MySQL, Kong, Redis, AWS, Docker, SocketIO, RESTful APIs, Jira, Git,Ubuntu-linux\")\n",
    "embedding2  =model.encode(\"Proficiency in server-side languages (e.g., Python, Java, Node.js).Experience with database management (SQL, NoSQL).Understanding of RESTful API design.\")\n",
    "\n",
    "print(embedding1.shape)\n",
    "print(embedding2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5155]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "cosine_sim = cos_sim(embedding1, embedding2)\n",
    "print(cosine_sim)\n",
    "#observed dismilar content with values of similarity less than <2.5/3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using cross encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 1. Load a pre-trained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.379882,  -9.711462], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Predict scores for a pair of sentences\n",
    "scores = model.predict([\n",
    "    (sentence4, sentence2),\n",
    "    (sentence4, sentence3),\n",
    "])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using mistral AI model to predict similarity score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experience = '''\n",
    "    I have 2 year of experience in software engineering, machine learning, and AI research, with a strong focus on deep learning, computer vision, and backend development. My expertise spans across multiple frameworks and technologies, including TensorFlow, PyTorch, Python, Flask, MongoDB, MySQL, Docker, AWS, and ReactJS.\n",
    "\n",
    "Research Experience\n",
    "As a Student Researcher at Sardar Vallabhbhai Patel Institute of Technology (Oct 2023 - Jul 2024), I worked on Speech Emotion Recognition (SER), leveraging deep learning and signal processing techniques to enhance emotion classification from speech. I explored two key approaches:\n",
    "\n",
    "Spectrogram-based deep learning model – Used spectrograms of audio data as input to a pre-trained CNN model, extracting deep features for classification.\n",
    "Acoustic feature-based model – Extracted features such as MFCC, ZCR, and RMS from raw audio and trained a 1D CNN + LSTM model, achieving state-of-the-art results.\n",
    "This research involved extensive experimentation with TensorFlow, PyTorch, and Librosa, applying advanced feature engineering and deep learning architectures.\n",
    "Industry Experience\n",
    "Previously, as an SDE Intern at CoRider (May 2023 - Sep 2023), I contributed to the backend development of a social ride-sharing app, building robust and scalable APIs. My key contributions included:\n",
    "\n",
    "Developing end-to-end RESTful APIs using Flask and Python.\n",
    "Implementing real-time chat functionality using SocketIO.\n",
    "Setting up gRPC-based communication between microservices.\n",
    "Integrating AWS services, managing MongoDB and MySQL databases, and working with Kong API Gateway.\n",
    "Deploying services using Docker and handling distributed systems.\n",
    "Notable Projects\n",
    "Speech Emotion Recognition – Fine-tuned 1D CNN, 1D CNN + LSTM, and 1D CNN + BiLSTM models for emotion classification from speech data. Employed ensemble learning techniques to further enhance performance.\n",
    "Exercise Correctly – Built a web app that analyzes exercise poses using PoseNet to extract key points and compare them with ideal poses using cosine similarity. Scraped yoga pose datasets using Scrapy. The frontend was developed using ReactJS and TailwindCSS, while the backend used Flask-RESTful.\n",
    "Visual Question Answering (VQA) – Fine-tuned the multimodal LLM Moondream on a VQA dataset and deployed it using Hugging Face libraries and Gradio for real-time inference.\n",
    "Technical Expertise\n",
    "My skill set includes deep learning, computer vision, natural language processing, backend development, and cloud computing. I am proficient in machine learning techniques, including classification, linear and logistic regression, decision trees, gradient descent, recommender systems, and supervised/unsupervised learning. Additionally, I have hands-on experience in database management, API development, containerization, and distributed computing.\n",
    "\n",
    "With a strong foundation in AI research and software development, I am passionate about solving real-world problems through cutting-edge machine learning models, scalable architectures, and innovative AI applications.\n",
    "'''\n",
    "\n",
    "moderate_match = '''\n",
    "Zeta Global seeks a visionary backend developer to join our Data Cloud team and spearhead its evolution with Generative AI. By integrating this revolutionary tech, you'll craft next-generation data products, unlocking powerful solutions for specific client challenges. This role offers the chance to master the marketing tech landscape, work on cutting-edge AI, and become a pioneer in its application for marketing.\n",
    "\n",
    "\n",
    "About the role: \n",
    "\n",
    "The expectations from this role are two-fold. \n",
    "\n",
    "Backend Developer who can perform data analysis and create outputs for Gen AI related tasks while supporting standard data analysis tasks. \n",
    "Gen AI expert who can effectively understand and translate business requirements and provide a Gen AI powered output independently.\n",
    "\n",
    "The person should be able to: \n",
    "\n",
    "Analyse data as needed from the data tables to generate data summaries and insights that are used for Gen AI and non-Gen AI work. \n",
    "Collaborate effectively with cross-functional teams (engineering, product, business) to ensure alignment and understanding. \n",
    "Create and use AI assistants to solve business problems. \n",
    "Comfortable providing and advocating recommendations for a better user experience. \n",
    "Support product development teams, enabling them to create and manage APIs that interact with the Gen AI backend data and create a next gen experience for our clients. \n",
    "Visualize and create data flow diagrams and materials required for effective coordination with devops teams. \n",
    "Manage the deployment of related APIs in Kubernetes or other relevant spaces \n",
    "Provide technical guidance to the UI development and data analyst teams on Gen AI best practices. \n",
    "Coordinate with business teams to ensure the outputs are aligned with expectations. \n",
    "Continuously integrating new developments in the Gen AI space into our solutions and provide product and non-product implementation ideas to fully leverage potential of Gen AI.\n",
    "\n",
    "The person should have:\n",
    "\n",
    "Proven experience as a data analyst, with a strong track record of delivering impactful insights and recommendations. \n",
    "Strong working knowledge of OpenAI, Gemini or other Gen AI platforms, and prior experience in creating and optimizing Gen AI models. \n",
    "Familiarity with API and application deployment, data pipelines and workflow automation. \n",
    "High-agency mindset with strong critical thinking skills. \n",
    "Strong business acumen to proactively identify what is right for the business. \n",
    "Excellent communication and collaboration skills. \n",
    "\n",
    "Technical Skills: \n",
    "\n",
    "Python\n",
    "SQL \n",
    "AWS Services (Lambda, EKS) \n",
    "Apache Airflow \n",
    "CICD (Serverless Framework) \n",
    "Git \n",
    "Jira / Trello\n",
    "\n",
    "It will be great to have:\n",
    "\n",
    "Good understanding of marketing/advertising product industry. \n",
    "At least 1 Gen AI project in production. \n",
    "Strong programming skills in Python or similar languages. \n",
    "Prior experience in working as Devops engineer or have worked closely with Devops. \n",
    "Strong background in data management.\n",
    "\n",
    "'''\n",
    "\n",
    "perfect_match = '''\n",
    "About the Role\n",
    "We are looking for a highly skilled AI/ML Engineer with strong expertise in deep learning, machine learning, and backend development. The ideal candidate should have experience in building and fine-tuning AI models, developing scalable backend systems, and deploying applications on cloud platforms. This role involves working on cutting-edge projects in computer vision, NLP, and multimodal AI, while also contributing to backend architecture, API development, and system optimization.\n",
    "\n",
    "Key Responsibilities\n",
    "AI & Machine Learning\n",
    "Develop, fine-tune, and deploy deep learning models using TensorFlow, PyTorch, and Hugging Face libraries.\n",
    "Work on Speech Emotion Recognition (SER), Visual Question Answering (VQA), and pose estimation applications.\n",
    "Implement and optimize 1D CNN, LSTM, BiLSTM, and ensemble learning models for various AI tasks.\n",
    "Utilize Librosa, pandas, NumPy, and Matplotlib for data preprocessing, feature extraction, and visualization.\n",
    "Conduct hyperparameter tuning, model evaluation, and performance optimization.\n",
    "Backend Development & System Architecture\n",
    "Design and develop scalable RESTful APIs using Flask and Flask-RESTful.\n",
    "Implement real-time features such as WebSockets and SocketIO for chat applications.\n",
    "Develop gRPC-based microservices for efficient inter-service communication.\n",
    "Work with MongoDB, MySQL, and Redis for database management and optimization.\n",
    "Deploy applications using Docker and manage cloud infrastructure on AWS.\n",
    "Full-Stack & Web Development\n",
    "Build AI-powered web applications using ReactJS, TailwindCSS, and Gradio.\n",
    "Implement data scraping solutions using Scrapy for gathering training datasets.\n",
    "Ensure responsive UI/UX and smooth user interactions for AI-driven applications.\n",
    "Skills & Qualifications\n",
    "Must-Have:\n",
    "Strong experience with TensorFlow, PyTorch, Python, and Scikit-learn.\n",
    "Proficiency in Flask, REST APIs, MongoDB, MySQL, Redis, and Docker.\n",
    "Knowledge of machine learning concepts such as classification, regression, decision trees, and gradient descent.\n",
    "Experience in LLMs, multimodal models, and AI research.\n",
    "Hands-on experience with Ubuntu/Linux, Git, and Jira for development and collaboration.\n",
    "Familiarity with cloud services (AWS), containerization, and microservices architecture.\n",
    "Nice-to-Have:\n",
    "Experience with Gradio, Kong API Gateway, and PoseNet for real-time applications.\n",
    "Understanding of retrieval-augmented generation (RAG) and recommender systems.\n",
    "Strong interest in AI for real-world problem-solving and automation.\n",
    "Years of experience required: 2\n",
    "\n",
    "'''\n",
    "\n",
    "frontend_job = '''\n",
    "\n",
    "Responsible for front-end requirement analysis\n",
    "Design develop application and website User Interfaces\n",
    "Responsible for the integration of web applications and components with the HTML markup\n",
    "Responsible for the development of web pages, multimedia, GUIs\n",
    "Working with PSDs\n",
    "Utilizes wireframes and graphic pre-designs where appropriate\n",
    "Effectively develops in a clean, well structured, easily maintainable format.\n",
    "Responsible for meeting expectations and deliverables on time and in high quality.\n",
    "Bug Fixing / Issues reporting Documentation.\n",
    "Analyzing opportunities for improvement and its implementation\n",
    "Knowledge of UI best practices\n",
    "Practical experience in development of HTML, JavaScript, CSS, Jquery\n",
    "Solid understanding of navigation and GUI for maximizing usability\n",
    "Seamless integration of front-end to back-end functionality\n",
    "Should have working knowledge of using a latest development tools and techniques\n",
    "Front-end and some back-end development skills\n",
    "Must have good problem solving and analysis skills\n",
    "Team-player with strong communication collaboration skills\n",
    "LOCK Xcellence-IT, and have the KEY to Innovative, Timely, Reliable and Perfect Services.\n",
    "eXcel with Xcellence-IT!!!\n",
    "Get on board with us, to get Quality IT Consulting, Solutions Services!!\n",
    "When Xcellence-IT works... PROFIT follows!!!\n",
    "PROFIT just happens with Xcellence-IT!!\n",
    "Candidate should be any graduate/post graduate in Computer Science or related degree program\n",
    "Excellent communication presentation skills\n",
    "Atleast 1 years of relevant industry experience is required\n",
    " '''\n",
    "\n",
    "uiux_job = '''\n",
    "We are seeking talented Graphic Designers specializing in branding to join our team. The ideal candidate will possess a deep understanding of visual communication, user-centered design principles, and the ability to create compelling designs that amplify our technology solutions' impact. In this role, you will drive the creation of captivating branding, promotional materials, and user-friendly application interfaces that resonate with our audience.\n",
    "\n",
    "\n",
    "Visual Branding: Craft and maintain a cohesive visual brand identity, designing logos, typography, color palettes, and brand assets that resonate with our tech-focused audience.\n",
    "Promotional Materials: Design captivating marketing collateral, including banners, infographics, and presentations, that effectively communicate our technology's value proposition.\n",
    "User-Centered Design: Conduct user research and usability testing to inform design decisions, ensuring our technology solutions align with user needs and preferences.\n",
    "Responsive Design: Create responsive designs that adapt seamlessly to various devices and screen sizes, enhancing user accessibility and engagement.\n",
    "Visual Storytelling: Craft custom graphics, illustrations, and visual narratives that convey complex technological concepts in an engaging and easily understandable manner.\n",
    "Innovative Creativity: Bring innovative design ideas to the table, pushing the boundaries of design conventions to create unique and memorable experiences.\n",
    "Cross-Functional Collaboration: Partner with marketing teams to design visually impactful campaigns and collaborate with developers to ensure design implementation aligns with intended user experiences.\n",
    "Visual Trends: Stay updated on design trends and emerging technologies to ensure our designs remain current and resonant within the tech industry.\n",
    "Application Interface Design: Collaborate with development teams to create user interfaces for web and mobile software applications, focusing on intuitive interactions and streamlined user experiences.\n",
    "Wire framing & Prototyping: Develop wireframes and interactive prototypes to visualize and iterate on application interfaces, ensuring optimal usability.\n",
    "\n",
    "Requirements\n",
    "\n",
    "Graphic Design Expertise: Demonstrated proficiency in graphic design with a portfolio showcasing branding, promotional materials.\n",
    "Design Tools: Proficiency in design tools such as Adobe Creative Suite (Illustrator, Photoshop), Coreldraw, Figma\n",
    "Degree: A degree in Graphic Design, Visual Communication, UI/UX Design, or a related field is preferred.\n",
    "Innovative Thinking: Creative mindset that pushes the boundaries of design norms to create visually stunning and impactful designs.\n",
    "User-Centered Mindset: Ability to empathize with users, translating their needs into intuitive and appleaing design solutions.\n",
    "Collaboration: Effective communication and collaboration skills to work closely with multidisciplinary teams.\n",
    "Responsive Design: Knowledge of responsive design principles to ensure seamless experiences across devices.\n",
    "Advantage: Web and Mobile application interface design and wire framing & prototyping skills. Proficiency in tools like Figma, Sketch, or similar.\n",
    "\n",
    "\n",
    "\n",
    " '''\n",
    "\n",
    "aiml_engineer_intern =''' \n",
    "\n",
    "Refonte Learning is seeking enthusiastic individuals for our prestigious Data Science Study and Internship Program. This intensive initiative offers a unique opportunity to collaborate closely with our seasoned data science team on diverse and impactful projects.\n",
    "\n",
    "Refonte Learning is seeking enthusiastic individuals who are looking to learn Data Science from beginning to advanced level while also working on live projects globally. RIGTIP (Refonte Infini Global Training & Internship Program) is designed as a manner that offers you to work in a flexible work environment but also offers working with people in a global team from Oceania, Asia, Europe, & American continents.\n",
    "\n",
    "Job Description:\n",
    "We are excited to offer an internship opportunity for individuals passionate about the convergence of AI, Data Science, DevOps, and Cloud technologies. As an AI, Data Science, DevOps, and Cloud Intern, you will have the unique opportunity to gain hands-on experience in these dynamic and interconnected fields, working on innovative projects and collaborating with experienced professionals.\n",
    "Responsabilities:\n",
    "Collaborate with cross-functional teams to develop, deploy, and maintain AI-driven solutions.\n",
    "Assist in collecting, cleaning, and analyzing data from various sources to derive actionable insights.\n",
    "Contribute to the design and implementation of scalable data pipelines for model training and deployment.\n",
    "Support the integration of machine learning models into production systems using DevOps best practices.\n",
    "Participate in designing and optimizing CI/CD pipelines for continuous integration, testing, and deployment of AI applications on cloud platforms.\n",
    "Assist in infrastructure provisioning, configuration, and monitoring using cloud services such as AWS, Azure, or Google Cloud.\n",
    "Work closely with data scientists and engineers to understand business requirements and translate them into technical solutions.\n",
    "Research and experiment with emerging technologies and tools in AI, Data Science, DevOps, and Cloud domains.\n",
    "Collaborate on documentation efforts to ensure knowledge sharing and best practices across the team.\n",
    "Projects You Will Work On:\n",
    "Multi Cloud AI Infrastructure Configuration, Automation and Deployment\n",
    "Full Stack AI DevOps & Development\n",
    "Generative AI model, Large Language Models and Foundations models to transform input to output. NB: Input can be text, images, audios or videos; Output can also be text, images, audios or videos\n",
    "Finance Fraud Detection: Develop advanced fraud detection algorithms leveraging financial data analysis.\n",
    "Recommender System: Contribute to personalized recommendation systems, enhancing user experiences across platforms.\n",
    "Sentiment Analysis: Explore sentiment analysis to extract insights from textual data, shaping user sentiment understanding.\n",
    "Chatbots: Engage in intelligent chatbot development, revolutionizing customer interactions and support.\n",
    "Image/Audio Video Classification: Push boundaries with multimedia technology by working on image and audio video classification projects.\n",
    "Text Analysis: Uncover hidden patterns in textual data through sophisticated text analysis techniques.\n",
    "Roles & Responsibilities:\n",
    "Collaborate with our esteemed data science experts to collect, clean, and analyze extensive datasets, honing skills in data preprocessing and visualization.\n",
    "Contribute to the development of predictive models and algorithms, employing cutting-edge machine learning techniques to solve real-world challenges.\n",
    "Work closely with team members to design, implement, and evaluate experiments, fostering a collaborative and innovative environment.\n",
    "Stay updated with the latest industry trends and best practices in data science, applying newfound knowledge to enhance project outcomes.\n",
    "Qualifications:\n",
    "Currently pursuing any degree showcasing a strong commitment to continuous learning and professional growth.\n",
    "Exceptional written and verbal communication skills, vital for effective collaboration and articulation of complex ideas.\n",
    "Demonstrated ability to work both independently and as part of a cohesive team, highlighting adaptability and strong teamwork capabilities.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90\n"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "# from google.colab import userdata\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "my_secrets = dotenv_values(\".env\")\n",
    "\n",
    "\n",
    "# api_key = userdata.get('MISTRAL_API_KEY')\n",
    "api_key = my_secrets[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model = model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # \"content\": f\"You are a recruiter/ hiring manager looking for the best fit for a job against a candidate resume. The non-negotiables to find the best match are same skills, years of experience required and context of experience that is relevant to job expectations and responsiblities.Calculate the similarity score (0 lowest-1highest) between 2 groups of sentences, one is candidate experience and other is job description. The similarity score should be calculated based on skills matched in the sentence both lexically and semantically. If the must have or mandatory skills or statements are satisfied or are matched then give a high score. Similarly if contect of experience aligns with expectations and responsibilities give a good score. Make sure the matches with high score satisfy the expected years of experience in job listing.If the candidate has no experience or has done work in completely different domain and no skills coincide then give a low score. Give a moderate score if some skills match.Only give the score as output to the query. Avoid being biased over formal education required, focus on skills and experience.Sentence 1: {my_experience} and Sentence 2: {aiml_engineer_intern}\"\n",
    "            \"content\": f'''\n",
    "                [INST] [SYS]\n",
    "                You are an experienced technical recruiter specializing in matching candidates to job descriptions with precision and objectivity. Your task is to analyze the match between a candidate's experience and a job posting.\n",
    "                [/SYS]\n",
    "\n",
    "                Calculate a similarity score (0.0-1.0, with two decimal places) between the candidate experience and job description below.\n",
    "\n",
    "                SCORING CRITERIA:\n",
    "                1. SKILLS MATCH (50%): Evaluate both lexical and semantic matches between technical skills mentioned\n",
    "                2. CONTEXT RELEVANCE (30%): Assess how well the candidate's work context aligns with the job responsibilities\n",
    "                3. EXPERIENCE DURATION (20%): Verify if the candidate meets the required years of experience\n",
    "\n",
    "                IMPORTANT GUIDELINES:\n",
    "                - Mandatory/must-have skills must be present for scores above 0.7\n",
    "                - Ignore formal education requirements; focus exclusively on skills and experience\n",
    "                - If candidate's domain is completely different with no overlapping skills, score below 0.3\n",
    "                - For partial skill matches, assign scores between 0.3-0.7 based on relevance\n",
    "                - Output ONLY the numerical score (e.g., \"0.75\") with no explanation or reasoning\n",
    "\n",
    "                CANDIDATE EXPERIENCE:\n",
    "                {my_experience}\n",
    "\n",
    "                JOB DESCRIPTION:\n",
    "                {perfect_match}\n",
    "                [/INST]\n",
    "            \n",
    "            \n",
    "            '''\n",
    "        },],\n",
    "\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better approach for skill matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create skill matching based on the above and non-negotiable skill matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
